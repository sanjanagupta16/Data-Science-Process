---
title: "Airbnb"
author: "Sanjana Gupta"
date: "30/01/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
always_allow_html: yes
---

#### GitHub Repo - 

Importing Libraries and setting cwd
```{r libraries}
library(tidyverse)
library(plotly)
library(ggplot2)
library(naniar)
library(leaflet)
library(htmltools)
library(choroplethr)
library(dplyr)
library(choroplethrMaps)
library(ggplot2)
library(gridExtra)
library(ggmap)
library(htmlwidgets)
library(mapview)
library(dplyr)
library(plotly)
library(devtools)
library(kableExtra)
library(here)

#setwd("~/Desktop/Winter 2020/Data 598C Data Science Process/Data Science Project")
#setwd(here("/Data Science Project"))
```

Importing data and creating a training dataset
```{r import-data}

data1 <- read.csv(file = "data/listings.csv", header = TRUE)
data2 <- read.csv(file = "data/calendar.csv")
data3 <- read.csv(file = "data/reviews.csv")

data_train <- data1
```

Viewing the data in different formats
```{r view-data}
#View(data_train)

#to view data kinda nicely - uses dplyr
#glimpse(data_train)
#str(data1)
#summary(data_train)
#head(data_train, 1000)
#tail(data_train, 50)
```

## Data Understanding & Data Cleanng

1. Data Cleaning - removing columns
```{r data-clean}
#cols_to_delete <- c("last_scraped", "thumbnail_url", "host_picture_url", "medium_url", "picture_url", "xl_picture_url", "host_thumbnail_url", "host_picture_url")
#select(data_train, -contains("url"))
data_train$last_scraped <- NULL
data_train$thumbnail_url <- NULL
data_train$host_picture_url <- NULL
data_train$medium_url <- NULL
data_train$picture_url <- NULL
data_train$xl_picture_url <- NULL
data_train$host_thumbnail_url <- NULL
data_train$host_picture_url <- NULL
data_train$host_url <- NULL
data_train$scrape_id <- NULL
data_train$experiences_offered <- NULL
data_train$neighborhood_overview <- NULL
data_train$host_about <- NULL
data_train$host_id <- NULL
data_train$host_verifications <- NULL
data_train$host_has_profile_pic <- NULL
data_train$host_identity_verified <- NULL
data_train$calendar_last_scraped <- NULL
data_train$license <- NULL
data_train$instant_bookable <- NULL
data_train$require_guest_profile_picture <- NULL
data_train$require_guest_phone_verification <- NULL
data_train$summary <- NULL
data_train$notes <- NULL
data_train$space <- NULL
data_train$description <- NULL
data_train$transit <- NULL
data_train$host_since <- NULL
data_train$host_neighbourhood <- NULL
data_train$market <- NULL
data_train$country_code <- NULL
data_train$is_location_exact <- NULL

rownames(data_train) <- NULL

#Viewing the data
#glimpse(data_train)
#summary(data_train$is_location_exact)
```

2. Converting Data type for price and cleaning fee to numeric
```{r convert-num}
data_train$price <- sub("\\$","",data_train$price)
data_train$price <- sub(",","",data_train$price)
data_train$price <- as.integer(data_train$price)

data_train$cleaning_fee <- sub("\\$","",data_train$cleaning_fee)
data_train$cleaning_fee <- sub(",","",data_train$cleaning_fee)
data_train$cleaning_fee <- as.integer(data_train$cleaning_fee)
```

3. Changing data type of categorical variables to factor
```{r convert-factor}
data_train$host_response_time <- as.factor(data_train$host_response_time)
data_train$host_is_superhost <- as.factor(data_train$host_is_superhost)
data_train$neighbourhood_cleansed <- as.factor(data_train$neighbourhood_cleansed)
data_train$property_type <- as.factor(data_train$property_type)
data_train$room_type <- as.factor(data_train$room_type)
data_train$bed_type <- as.factor(data_train$bed_type)
data_train$calendar_updated <- as.factor(data_train$calendar_updated)
data_train$cancellation_policy <- as.factor(data_train$cancellation_policy)
```

4. Changing host reponse time and extra people from character to numeric
```{r convert-num2}
data_train$host_response_rate<- as.numeric(sub("%", "", data_train$host_response_rate))
data_train$host_response_rate <- data_train$host_response_rate/100
data_train$extra_people <- as.numeric(sub("\\$","",data_train$extra_people))
```

5. Checking if Price = 0 for any listings
```{r check-price}
0 %in% data_train$price
```
All Airbnb listings have a price associated with it

6. Removing rows with NA
```{r remove-NA}
#is.null(data_train$zipcode)
data_train %>% filter_all(all_vars(!is.na(.)))
data_train %>% filter_all(all_vars(complete.cases(.)))  
```

7. Removing rows with null values
```{r remove-null}
data_train %>% filter_all(all_vars(!is.null(.)))
data_train %>% filter_all(all_vars(complete.cases(.)))  
```

8. Getting a summary of all fields
```{r summary}
summary_df <- data.frame(summary(data_train))
#write.csv(summary_df, "summary.csv")
```

9. Adding log price column and log accommodates column --- Transformations
```{r log-Price}
data_train$log_price <- log(data_train$price)
data_train$log_acc <- log(data_train$accommodates)
```


10. Checking for missing values and plotting the data
```{r missing-data}
check_missing<- function(x){
  if (is.character(x)) sum(x=="") else sum(is.na(x))
}
NMISS<-data.frame(nmiss=sapply(data_train,check_missing))
#write.csv(NMISS, "missing.csv")

#plotting missing data
missingdata <- data_train
missingdata[missingdata == ""] <- NA
missingdata <- missingdata %>% select(host_is_superhost, review_scores_rating,
                                      host_response_time, name, zipcode, latitude,longitude,
                                      host_location, host_response_rate,neighbourhood_cleansed,
                                      property_type, price,weekly_price, monthly_price, bedrooms, bathrooms)
gg_miss_var(missingdata) + labs(title = "Missing Values Plot",y = "Missing Data", x = "Attribute")  + theme_bw() + theme(text=element_text(color = "dark blue")) 
```

11. Replacing missing values
```{r replace-missing}
data_train$review_scores_rating <- ifelse(is.na(data_train$review_scores_rating)==T,97,data_train$review_scores_rating)
data_train$host_response_rate <- ifelse(is.na(data_train$host_response_rate)==T,97,data_train$host_response_rate)

#Using same plot as before to check the values
gg_miss_var(missingdata) + labs(title = "Missing Values Plot",y = "Missing Data", x = "Attribute")  + theme_bw() + theme(text=element_text(color = "dark blue")) 
```

## Data Understanding - plots

1. Analysing neighborhood grouping
```{r neighborhood}
#In neighborhood group cleansed, there are 794 rows with "Other Neighborhoods"
#Need to fix this - maybe look at neighorhood cleansed column instead?
#Looking at categorical data now
sorted <- sort(table(data_train$host_neighbourhood), decreasing = TRUE)
#head(subset(data_train, select = 'neighbourhood_group_cleansed'))
fact <- factor(data_train$neighbourhood_group_cleansed)
count(data_train, 'neighbourhood_group_cleansed')
count(data_train, 'neighbourhood_cleansed')

#Getting a count of listings per neighborhood
#write.csv(neigborhood_data, "neighborhoodcount.csv")
#count(data_train$neighbourhood_cleansed)
plot(data_train$neighbourhood_cleansed, xlab = 'Neighborhoods', ylab = 'Count')
neighborhood <- (data_train$neighbourhood_cleansed)
#x <- sort(count((neighborhood)))
#arrange(data_train, neighbourhood_cleansed)
neighborhood_data <- data_train[order(data_train[,21] ),]
#summary(neighborhood_data$neighbourhood_cleansed)
```

```{r plot1}
#Trying to fix "Other Neighborhoods" value in neighborhood group cleaned column
#for(i in data_train)
 # if(i[neighbourhood_group_cleansed] == "Other neighborhoods")
  #  i[neighbourhood_group_cleansed] <-  i[neighborhood_cleansed]

#Plotting count of listings per neighborhood
neigborhood_data <- table(data_train$neighbourhood_cleansed)

barplot(sort(table(data_train$neighbourhood_group_cleansed), decreasing = TRUE), ylab = "Count",horiz = FALSE , main = "Distribution of Listings Per Neighborhood", beside = FALSE)
```

```{r plot2}
#barplot(table(data_train$neighbourhood_group_cleansed), density = 20, ylab = "Count",horiz = FALSE , main = "Distribution of Listings Per Neighborhood", beside = FALSE) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(data_train, aes(neighbourhood_group_cleansed)) + geom_bar(na.rm = TRUE, stat = "count") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

2. Looking at some more plots - Count of Host Listings
```{r count-listings}
#barplot(data_train$host_listings_count, main = "Count of Host Listings", xlab = "", ylab = "Count") 
ggplot(data_train, aes(host_listings_count)) + geom_bar(na.rm = TRUE) + xlim(0,21) 
```
# Most hosts have a single Airbnb listing.

3. Looking at Types of Airbnb properties
```{r property_type}
#barchart(data_train$property_type, main = "Types of Airbnb Properties", xlab = "Count")
prop_type <- table(data_train$property_type)
barplot(table(data_train$property_type), ylab = "Count",horiz = FALSE, main = "Types of Airbnb Properties", beside = FALSE, las = 1)

ggplot(data_train, aes(property_type)) + geom_bar(na.rm = TRUE, stat = "count") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
#plot(data_train$host_is_superhost)
```

4. Prices per Neighborhood
```{r price-neighborhood}
z = table(data_train$room_type,data_train$neighbourhood_group)
kable(z)  %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive"))
```


```{r boxplot1}
data_train %>% boxplot(price ~ neighbourhood_group_cleansed,data = ., main="Box Plot of price vs neighbourhood", 
                     ylab="neighbourhood", xlab="Price",horizontal=TRUE)
```

5. Number of listings per neighborhood
```{r listings}
ggplot(data_train, aes(x = fct_infreq(neighbourhood_cleansed), fill = room_type)) +
    geom_bar() +
    labs(title = "No. of listings by neighborhood",
         x = "Neighborhood", y = "No. of listings") +
    theme(legend.position = "bottom") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
Looks messy, want to consider looking at only the top 10 neighborhoods

6. Top 10 neighborhoods - doesn't work - need to fix this
```{r top10}
#top_10 <- data_train %>% group_by(neighborhood_cleansed) %>% tally()
#top_10 <- data_train %>% top_n(n = 10, wt = neighbourhood_group_cleansed) %>% arrange(neighbourhood_group_cleansed) %>% #summarize(neighbourhood_group_cleansed = n())

top_10 <- data_train[data_train$neighbourhood_group_cleansed %in% names(sort(table(data_train$neighbourhood_group_cleansed), decreasing = TRUE)[0:1]),]
#top_10 <- data_train %>% top_n(10) %>% group_by(neighbourhood_group_cleansed) %>% tally() 
top_10.val <- table(top_10$neighbourhood_group_cleansed)
kable(top_10.val)
```

7. Looking at outliers for price
```{r outliers}
ggplot(data=data_train, aes(price)) + 
  geom_histogram(fill="red") + 
  labs(title="Histogram of Price") +
  labs(x="Price", y="Count")
# Percentile of price
quantile(data_train$price, c(.9, .95, .97, 0.975, 0.98, 0.99, 0.995, 0.999, 0.9999))
```
8. Room Type Analysis
# For a private room
```{r private-room}
Private_rooms <- data_train %>% filter(room_type == "Private room")
Private_rooms$price %>% summary()
```

# For an entire apartment

```{r entire-apt}
entire_house <- data_train %>% filter(room_type == "Entire home/apt")
entire_house$price %>% summary()
```

#Shared room
```{r shared-room}
shared_room <- data_train %>% filter(room_type == "Shared room")
shared_room$price %>% summary()
```

9. Average prices for each room type
```{r avg-price}
listingdf <- read.csv('data/listings.csv')
zipReviews <- listingdf %>% group_by(zipcode = zipcode) %>% summarise(avg_loc_review = mean(review_scores_location, na.rm = TRUE))

average_price <- data_train %>% group_by(room_type) %>% summarise(price = mean(price))
colnames(average_price)[1] <- "Room Type"
colnames(average_price)[2] <- "Average Price"
print((average_price))
```

10. Top 50 most expensive listings
```{r patial Data 1.3, echo=FALSE, message=FALSE, warning=FALSE}
top_df <- data_train %>% top_n(n = 50, wt = log_price)

# get background map
top_height <- max(top_df$latitude) - min(top_df$latitude)
top_width <- max(top_df$longitude) - min(top_df$longitude)
top_borders <- c(bottom  = min(top_df$latitude)  - 0.1 * top_height,
                 top     = max(top_df$latitude)  + 0.1 * top_height,
                 left    = min(top_df$longitude) - 0.1 * top_width,
                 right   = max(top_df$longitude) + 0.1 * top_width)

top_map <- get_stamenmap(top_borders, zoom = 12, maptype = "toner-lite")

# map of top 50 most expensive listings
ggmap(top_map) +
    geom_point(data = top_df, mapping = aes(x = longitude, y = latitude,
                                        col = price)) +
    scale_color_gradient(low = "blue", high = "red")
```

## Model Selection

1. Clustering
Used Clustering to compare which areas of Seattle have a higher concentration of airbnb listings.

Plotting the listings on the map of Seattle
```{r clustering}
#Reading Listings Data
listingdf <- read.csv('data/listings.csv')
#Creating a link for each pop up

#Creating Listings across Seattle
map <- leaflet(listingdf) %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,labelOptions = labelOptions(noHide = T),
             clusterOptions = markerClusterOptions(),
             popup = paste0("<b> Name: </b>", listingdf$name , "<br/><b> Host Name: </b>", 
                            listingdf$host_name, "<br> <b> Price/night: </b>", listingdf$price, "<br/><b> Room Type: </b>", 
                            listingdf$room_type, "<br/><b> Property Type: </b>", listingdf$property_type
             )) %>% 
  setView(-122.335167, 47.608013, zoom = 11) %>%
  addProviderTiles("CartoDB.Positron")
map
mapshot(map, url = paste0(getwd(),"/map.html"))
```
This shows listings in a clustered fashion. Clicking on a cluster zooms into the listings belonging to it.
Clicking on a pin gives you a pop up with some details about the property.
We can see that most of the listings are clustered around Downtown and Cap Hill.

2. Linear Regression without interaction

Which variables influence price?
Variables selected - bathrooms, price, property type, accomodates, bedrooms, room type, host is superhost, cancellation policy, availability_365, cleaning_fee
### Added cleaning_fee as a new predictor
```{r LR}
LM_model1 <- summary(lm(formula = (price) ~ room_type + accommodates + bedrooms + bathrooms + property_type + host_is_superhost + cancellation_policy + availability_365 +cleaning_fee, data = data_train))
plot(price ~room_type + accommodates + bedrooms + bathrooms + property_type + factor(neighbourhood_cleansed) + host_is_superhost, data = data_train) + abline(lm(formula = price ~ room_type + accommodates + bedrooms + bathrooms, data = data_train))
LM_model1
#qqnorm(LM_model1$residuals, main = "Normal qq plot of residuals")

```
Results:

Private and Shared rooms, accommodates, bedrooms, bathrooms have a significant impact on price.
So does Property Type = Boat - which is weird.
R-squared is 60%, which is not bad


3. Taking log(price) with multiple linear regression:
### Added cleaning_fee as a new predictor
```{r lR-with-logprice}
LM_model2 <- summary(lm(formula = log_price ~ room_type + accommodates + bedrooms + bathrooms + property_type + host_is_superhost +cancellation_policy + availability_365 + cleaning_fee, data = data_train))
plot(price ~room_type + accommodates + bedrooms + bathrooms + factor(neighbourhood_cleansed) + host_is_superhost + cancellation_policy + availability_365, data = data_train) + abline(lm(formula = log_price ~ room_type + accommodates + bedrooms + bathrooms, data = data_train))
LM_model2
```
Results:
Transforming price to log has a higher R-squared value of 65%. 
Going forward, using log_price instead price.

4. Taking log for accomodates: log-accommodates
### Added cleaning_fee as a new predictor
```{r log-acc}
LM_model3 <- summary(lm(formula = log_price ~ room_type + log_acc + bedrooms + bathrooms + property_type + host_is_superhost + cleaning_fee + cancellation_policy, data = data_train))
plot(price ~room_type + log_acc + bedrooms + bathrooms + property_type + availability_365 + host_is_superhost + cancellation_policy + cleaning_fee, data = data_train) + abline(lm(formula = log_price ~ room_type + log_acc + bedrooms + bathrooms, data = data_train))
LM_model3
```
Using transformation for accommodates column, we get a 66.3% R-squared value. Going forward, using log_accommodates.

5. Linear Regression with interaction
### Added cleaning_fee as a new predictor
```{r LR-interacion}
LM_model4 <- summary(lm(formula = log_price ~ room_type * log_acc * bedrooms + bathrooms * property_type * cancellation_policy * availability_365 * cleaning_fee, data = data_train))
plot(log_price ~room_type * log_acc * bedrooms * bathrooms * property_type,data = data_train) + abline(lm(formula = price ~ room_type + log_acc + bedrooms + bathrooms, data = data_train))
LM_model4

```
Results:
R-squared is at 69.35%. 

6. Pairwise comparison

```{r pairwise}
# price vs bathrooms
p1 <- ggplot(data_train, aes(x=bathrooms, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

# price vs accommodates
p2 <- ggplot(data_train, aes(x=log_acc, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

# price vs bedrooms
p3 <- ggplot(data_train, aes(x=bedrooms, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

# price vs room_type
p4 <- ggplot(data_train, aes(x=room_type, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

#price vs host_is_superhost
p5 <- ggplot(data_train, aes(x=host_is_superhost, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

p6 <- ggplot(data_train, aes(x=cancellation_policy, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

p7 <- ggplot(data_train, aes(x=cleaning_fee, y=log_price)) +
  geom_point(colour = "orange", size = 1.5) +
  geom_smooth(method='lm', color='red') +
  ylab("price")

# combining all plots
grid.arrange(p1, p2, p3, p4,p5,p6, p7, ncol = 2)
```

7. Preparing test and train data 
```{r}
library(caTools)
data_train <- data_train %>% drop_na(log_price) %>% drop_na(log_acc) %>% drop_na(bedrooms) %>% drop_na(bathrooms) %>% drop_na(room_type) %>% drop_na(host_is_superhost) %>% drop_na(cancellation_policy) %>% drop_na(availability_365) %>% drop_na(cleaning_fee)

sample_size <- floor(0.75 * nrow(data_train))

set.seed(1)
train_ind <- sample(seq_len(nrow(data_train)), size = sample_size)
train <- data_train[train_ind,]
test <- data_train[-train_ind,]
```


8. Predicting Price using Linear Regression Model
### Added cleaning_fee as a new predictor
```{r predict-price}
set.seed(100)
#trainingRowIndex <- sample(1:nrow(data_train), 0.8 *nrow(data_train))
#trainingData <- data_train[trainingRowIndex,]
#testData <- data_train[-trainingRowIndex,]

lm_model <- lm(formula = log_price ~ room_type * log_acc * bedrooms * bathrooms * host_is_superhost * cancellation_policy * availability_365 * cleaning_fee, data = train)
price_pred <- predict(lm_model, test)

summary(lm_model)

LM_pred <- data.frame(cbind(Actual = test$log_price, Predicted= price_pred))
correlation_accuracy <- cor(LM_pred)

head(LM_pred)
correlation_accuracy
plot(lm_model)

#ggplot(data = testData, aes(x = actual_pred$Actual, y = actual_pred$Predicted)) +
#geom_point() +
#stat_smooth(method = "lm", col = "dodgerblue3") +
#theme(panel.background = element_rect(fill = "white"),
#axis.line.x=element_line(),
#axis.line.y=element_line()) +
#ggtitle("Linear Model Fitted to Data") + ylab("Predicted") + xlab("Actuals")
```
R-squared value of 65.34%.
Update: R-squared value is 74%.

9. Correlation matrix
### Added cleaning_fee as a new predictor
```{r corr}
data.corr <- data_train %>% filter(!is.na(log_acc)) %>% filter(!is.na(bathrooms)) %>% filter(!is.na(bedrooms)) %>% filter(!is.na(availability_365)) %>% filter(!is.na(cleaning_fee)) %>%
  select(log_price, price, bedrooms, bathrooms, log_acc, availability_365, cleaning_fee)
kable(cor(data.corr)) %>% kable_styling()
```
Bedrooms, bathrooms and log_accommodate, cleaning fee have a correlation with log price but not a strong one.


10. Create a CART model - with log price and bedroom
```{r Cart1}
# Implement CART model
library(rpart)
library(rpart.plot)
CARTmodel1 = rpart(log_price ~ bedrooms, data = train, cp =0.001)
prp(CARTmodel1)
```
Making predictions

```{r pred1}
# Make predictions
predTest = predict(CARTmodel1, newdata = test)

#SSE
SSE = sum((predTest - test$log_price)^2)
cat("SSE = ",SSE)
# RMSE
RMSE = sqrt(mean((predTest - test$log_price)^2))
cat("\nRMSE = ",RMSE)

# Baseline
baseline = mean(train$log_price)
cat("\nbaseline = ",baseline)

# SSE of baseline model on testing set
SSEb = sum((baseline - test$log_price)^2)
cat("\nSSEb = ", SSEb)

# R^2
Rsquared = 1 - SSE/SSEb
cat("\nR squared = ",Rsquared)
```
11. Creating CART model to predict log(price) using variables: log(acc), bedrooms, bathrooms, room_type, host_is_superhost, cancellation_policy, cleaning_fee, availability_365
### Added cleaning_fee as a new predictor

```{r}
CARTmodel2 = rpart(log_price ~ log_acc + bedrooms + bathrooms + room_type + host_is_superhost + cancellation_policy + availability_365 + cleaning_fee, data = train, cp =0.001)
prp(CARTmodel2)
```
Make predictions:

```{r}
# Make predictions
predTest = predict(CARTmodel2, newdata = test)

#head(predTest)

#SSE
SSE = sum((predTest - test$log_price)^2)
cat("SSE = ",SSE)
# RMSE
RMSE = sqrt(mean((predTest - test$log_price)^2))
cat("\nRMSE = ",RMSE)

# Baseline
baseline = mean(train$log_price)
cat("\nbaseline = ",baseline)

# SSE of baseline model on testing set
SSEb = sum((baseline - test$log_price)^2)
cat("\nSSEb = ", SSEb)

# R^2
Rsquared = 1 - SSE/SSEb
cat("\nR squared = ",Rsquared)
```

5. Random Forest
### Added cleaning_fee as a new predictor
```{r RTF}
library(randomForest)
library(party)

set.seed(1)

RFmodel1 <- randomForest(formula = log_price ~ log_acc + bedrooms + bathrooms +room_type + property_type + host_is_superhost + cancellation_policy + availability_365 + cleaning_fee, data=train, nodesize = 100, ntree = 1000, mtry = 2, importance = TRUE, na.action = na.omit)

RFmodel1
#getTree(RFmodel1, 1)
#plot(RFmodel1)

round(importance(RFmodel1),2)
```

6. Using Random Forest to make predictions
### Added cleaning_fee as a new predictor
```{r predict}
# Make predictions
predTest <- predict(RFmodel1, newdata = test, type = "response")

RT_pred <- data.frame(cbind(Actual = test$log_price, Predicted= predTest))

RT_pred
```

7. Parameters for Random Forest 

````{r}
# SSE
SSE = sum((predTest - test$log_price)^2)
cat("SSE = ",SSE)

# RMSE
RMSE = sqrt(mean((predTest - test$log_price)^2))
cat("\nRMSE = ",RMSE)

# Baseline
baseline = mean(test$log_price)
cat("\nBaseline = ",baseline)

# SSE of baseline model on testing set
SSEb = sum((baseline - test$log_price)^2)
cat("\nSSEb = ",SSEb)

# R^2
Rsquared = 1 - SSE/SSEb
cat("\nRsquared = ",Rsquared)
```
Random Tree Forest model gives the highest R-squared value of 66%.

6. Parameter Tuning - Grid Search
```{r}
library(mlbench)
library(caret)
library(e1071)

set.seed(1)

trControl <- trainControl(method = "cv", number = 10, search = "grid")
rf_default <- train(log_price ~ log_acc + bedrooms + bathrooms + room_type + property_type + host_is_superhost + cancellation_policy + cleaning_fee, data = train, method = "rf", metric = "Rsquared", trControl = trControl)
print(rf_default)

```

7. ANOVA - to compare categorical data
```{r anova}
AOV_res <- summary(aov(log_price ~ factor(property_type) + factor(neighbourhood_cleansed), data = data_train))
AOV_res
```
Results:
As we can see, property type and neighborhood do have a significant impact on price since the p-value is much smaller than the significance level.

8. GLM

```{r glm}
glm_1 <- glm(log_price ~ log_acc + bedrooms + bathrooms + room_type + host_is_superhost + cancellation_policy + cleaning_fee, data = data_train, family = gaussian(link  = "log"))
summary(glm_1)
glm_1$coeff
```

## Model Evaluation
```{r}
hist(LM_pred)
hist(RT_pred)
```

Model is evaluated based on R-squared value i.e. % of variablility explained by the model.
Predicting price on:
1. Linear Regression with interaction has an R-squared value of 69.35%.
### Update: Linear Regression w/ interaction has an R-squared value of 74%.
2. Random Tree Forest has an R-square value of 66%.
Based on this, Linear Regression with interaction wins.

## Utility Function
1. For Linear Regression
```{r util-LR}
LM_pred$diff <- LM_pred$Actual - LM_pred$Predicted
diff <- sum(LM_pred$diff)
head(LM_pred)
cat("Sum of diff = ", diff)
```
A profit of $9.42 for this model.
### Update: Profit of $2454 is predicted by using a linear regression w/ interaction model.

2. Random Tree Forest
```{r util-R}
RT_pred$diff <- RT_pred$Actual - RT_pred$Predicted
diff2 <- sum(RT_pred$diff)

head(RT_pred)
cat("\n Diff = ",diff2)
```
Based on this model, a profit of $7.14 can be made.

Linear Regression wins.
